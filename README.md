# Auto-GPT
Auto-GPT represents an innovative, open-source endeavor that serves as a compelling demonstration of the exceptional prowess of the GPT-4 language model. This cutting-edge application leverages the remarkable abilities of GPT-4 to interconnect a series of language-based "thoughts" and autonomously accomplish diverse objectives defined by the user. By showcasing the self-directed operation of GPT-4, Auto-GPT not only pushes the frontiers of artificial intelligence but also exemplifies the vast possibilities that can be achieved through this remarkable technology.

# Simple test to communicate with "gpt-3.5-turbo"
Run simple_gpt.py
import openai: This line imports the openai module, which allows us to interact with the OpenAI API and make requests to their models.

openai.api_key = "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": Here, we set the API key to authenticate our requests with OpenAI's services. This key is provided by OpenAI and is used to identify and authorize the user.

completion = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=[{"role": "user", "content": "Write an essay about mobile phones"}]): This line creates a chat completion request using the OpenAI API. We use the openai.ChatCompletion.create() method to send a request to the GPT-3.5-turbo model. The messages parameter is a list of message objects, where each object represents a role (either "system", "user", or "assistant") and the content of the message. In this case, we have a single user message asking to write an essay about mobile phones.

print(completion.choices[0].message.content): Finally, we print the content of the response generated by the model. The completion.choices attribute contains a list of generated message objects. Since we only made a single completion request, we can access the first item in the list using [0]. Then, we access the message.content attribute to retrieve the actual generated essay text and print it to the console.

#Medium test to communicate with "gpt-3.5-turbo"
Run medium_gpt.py
import openai: This line imports the OpenAI library, which allows you to interact with the OpenAI API.

openai.api_key = "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": This line sets your OpenAI API key, which is required to authenticate and make requests to the API. Make sure to replace "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" with your actual API key.

messages = []: This line initializes an empty list called messages. It will store the conversation history between the user and the chatbot.

system_msg = input("What type of chatbot would you like to create?\n"): This line prompts the user to enter a system message, which will define the behavior or role of the chatbot.

messages.append({"role": "system", "content": system_msg}): This line adds the system message to the messages list as a dictionary with the keys "role" and "content". The role is set as "system", and the content is the message entered by the user.

print("Your new assistant is ready!"): This line displays a message to indicate that the chatbot is ready for interaction.

while input != "quit()":: This line starts a while loop that will continue until the user enters "quit()".

message = input(): This line prompts the user to enter their message/input.

messages.append({"role": "user", "content": message}): This line adds the user's message to the messages list as a dictionary with the role set as "user" and the content set as the user's input.

response = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=messages): This line sends a request to the OpenAI API using the openai.ChatCompletion.create() method. It passes the model name as "gpt-3.5-turbo" and the messages list as the conversation history.

reply = response["choices"][0]["message"]["content"]: This line extracts the assistant's reply from the API response and assigns it to the variable reply.

messages.append({"role": "assistant", "content": reply}): This line adds the assistant's reply to the messages list as a dictionary with the role set as "assistant" and the content set as the assistant's reply.

print("\n" + reply + "\n"): This line prints the assistant's reply, surrounded by newline characters for better readability.

#Serious test to communicate with "gpt-3.5-turbo"
Run serious_gpt.py
import openai: This line imports the OpenAI library, which allows you to interact with the OpenAI API.

import gradio: This line imports the Gradio library, which provides a user-friendly interface for creating interactive web-based demos.

openai.api_key = "####": This line sets your OpenAI API key, which is required to authenticate and make requests to the API. Replace "####" with your actual API key.

messages = [{"role": "system", "content": "You are a financial expert that specializes in real estate investment and negotiation"}]: This line initializes the messages list with a system message. The system message sets the initial behavior or role of the chatbot, specifying that it is a financial expert specializing in real estate investment and negotiation.

def CustomChatGPT(user_input): This line defines a function called CustomChatGPT that takes a user's input as a parameter.

messages.append({"role": "user", "content": user_input}): This line adds the user's input to the messages list as a dictionary with the role set as "user" and the content set as the user's input.

response = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=messages): This line sends a request to the OpenAI API using the openai.ChatCompletion.create() method. It passes the model name as "gpt-3.5-turbo" and the messages list as the conversation history.

ChatGPT_reply = response["choices"][0]["message"]["content"]: This line extracts the assistant's reply from the API response and assigns it to the variable ChatGPT_reply.

messages.append({"role": "assistant", "content": ChatGPT_reply}): This line adds the assistant's reply to the messages list as a dictionary with the role set as "assistant" and the content set as the assistant's reply.

return ChatGPT_reply: This line returns the assistant's reply.

demo = gradio.Interface(fn=CustomChatGPT, inputs="text", outputs="text", title="Real Estate Pro"): This line creates a Gradio interface called demo. It uses the CustomChatGPT function as the underlying function for processing user inputs and generating outputs. The inputs parameter is set to "text", indicating that users will input text, and the outputs parameter is also set to "text", indicating that the outputs will be text-based. The title parameter sets the title of the interface to "Real Estate Pro".

demo.launch(share=True): This line launches the Gradio interface. When share is set to True, it generates a publicly shareable link for the interface, allowing others to access and interact with it.

The Gradio interface will display a text input box where users can enter their messages, and the assistant's replies will be shown as text outputs. The conversation history is stored in the messages list, allowing the assistant to maintain context between user interactions.
